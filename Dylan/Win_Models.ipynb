{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models target value = ' Win ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>net_points</th>\n",
       "      <th>net_yard</th>\n",
       "      <th>net_turn</th>\n",
       "      <th>weekly_rank</th>\n",
       "      <th>spread</th>\n",
       "      <th>Win</th>\n",
       "      <th>WinSpread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1268</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>-104</td>\n",
       "      <td>-15</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0</td>\n",
       "      <td>-34</td>\n",
       "      <td>-325</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-302</td>\n",
       "      <td>-5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>-260</td>\n",
       "      <td>-5</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home  net_points  net_yard  net_turn  weekly_rank  spread  Win  \\\n",
       "0        1           0         0         0            2    -5.5  1.0   \n",
       "1        0           0         0         0            6     5.5  0.0   \n",
       "2        1           0         0         0           17    -1.0  0.0   \n",
       "3        0           0         0         0           15     1.0  1.0   \n",
       "4        1           0         0         0           27    -3.0  1.0   \n",
       "...    ...         ...       ...       ...          ...     ...  ...   \n",
       "4603     0         116      1268        -4           10     6.0  1.0   \n",
       "4604     1         112      -104       -15            7    -6.5  1.0   \n",
       "4605     0         -34      -325         0           13     6.5  0.0   \n",
       "4606     1          52      -302        -5            8    -3.0  0.0   \n",
       "4607     0          56      -260        -5           11     3.0  1.0   \n",
       "\n",
       "      WinSpread  \n",
       "0           1.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           1.0  \n",
       "...         ...  \n",
       "4603        1.0  \n",
       "4604        0.0  \n",
       "4605        1.0  \n",
       "4606        0.0  \n",
       "4607        1.0  \n",
       "\n",
       "[4608 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"new_final_df.csv\")\n",
    "cols = [0]\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "df.loc[df.Win == 0.5,'Win'] = 0\n",
    "df.loc[df.WinSpread == 0.5,'WinSpread'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Win', 'WinSpread'],axis=1)\n",
    "y = df['Win']\n",
    "y = y.astype('int')\n",
    "\n",
    "#Split to test and train \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.663\n",
      "Test set accuracy: 0.672\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "score = logreg.score(X_train, y_train)\n",
    "score2 = logreg.score(X_test, y_test)\n",
    "\n",
    "print (\"Training set accuracy:\", '%.3f'%(score))\n",
    "print (\"Test set accuracy:\", '%.3f'%(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 0 1 0 0 1 0 1 1 0]\n",
      "First 10 Actual labels: [1, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -0.3131046540322817\n",
      "Mean Squared Error: 0.32827187274041936\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metric\n",
    "r2 = metric.r2_score(y_test, predictions)\n",
    "mse = metric.mean_squared_error(y_test, predictions)\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgV1Z3/8ffndiOigBtgEBcE0SgY2dyFuI2imQyJxqhx1NEkyvyMiTGacUnGxIyJiVEnmzEajcS4RAdR4wouiEQFAVFZVMQdEQVFBRFp+P7+qLpQtN23b9t97+3bfF4+9XTdU1XnnNv9+OWcOlXnKCIwM7NErtIVMDNrSxwUzcwyHBTNzDIcFM3MMhwUzcwyaitdgZZSbafQBl0qXQ1rhkE7b1vpKlgzvPrqKyxatEgtyaOm63YRdcuLOjeWv3N/RIxoSXktUf1BcYMudNzp65WuhjXDPyf/vtJVsGbYd8+hLc4j6pYX/f/pxzP+0K3FBbZA1QdFM6sGAlXH3ToHRTMrPQG5mkrXoigOimZWHmrRbcmycVA0szJw99nMbF1uKZqZpYRbimZma8ktRTOzdXj02cwszwMtZmZrCXefzczW4ZaimVmeu89mZmsJqPFAi5nZWr6naGaW5+6zmdm63FI0M8twS9HMLKXWec1P0obARKAjSfz6v4i4QNLfgZ3S0zYFlkTEQEm9gTnA8+mxJyJiVKEyHBTNrDxa5zW/FcCBEbFUUgdgkqR7I+Lo/AmSLgXez1wzLyIGFluAg6KZlUHrDLRERABL048d0i3WlCIJ+Dpw4Gctozo6+WZW/fJd6KY26CZpamY7Zd1sVCNpBvA2MD4iJmcODwMWRsTcTNr2kp6S9IikYU1V0y1FMyu95s2nuCgiGl1CMCJWAQMlbQqMlTQgImamh48FbsqcvgDYNiIWSxoC3C6pf0R80Fj+bimaWRmk3editiJFxBJgAjACQFItcATw98w5KyJicbo/DZgH7FgoXwdFMyuPXE1xWwGSuqctRCR1Ag4GnksPHww8FxFv1Du/Jt3vA/QDXipUhrvPZlYerfPwdk9gdBrocsAtEXFXeuwY1u06AwwHLpRUB6wCRkXEu4UKcFA0s9JTq40+PwMMauTYfzSQNgYY05wyHBTNrDz8mp+Z2VpyUDQzSySrETgompklJJRzUDQzW8MtRTOzDAdFM7MMB0UzszylWxVwUDSzkhNyS9HMLCuXq46pFhwUzaws3FI0M8vzPUUzs3W5pWhmlvJAi5lZPX7Nz8wsT9XTfa6OMXIzq3qSitqayGNDSVMkPS1plqSfpuk/kTRf0ox0OzxzzbmSXpT0vKRDm6qnW4pmVhat1FJcARwYEUsldQAmSbo3PXZ5RPy6Xpm7kCxT0B/YCnhA0o7pioANckvRzEouP9DS0pZiJJamHzukWxS4ZCRwc7qq38vAi8AehcpwUDSz8lCRG3STNDWznbJONlKNpBnA28D4iJicHvqOpGckXStpszStF/B65vI30rRGuftsZqWnZr3mtygihjZ2MO36DkyXOh0raQDwR+BnJK3GnwGXAifT8CPjhVqWbimaWXm0Rvc5KyKWABOAERGxMCJWRcRq4GrWdpHfALbJXLY18GahfB0Uzaw8iu8+N55Fsrj9pul+J+Bg4DlJPTOnfRWYme7fCRwjqaOk7YF+wJRCZbj7XAEdN6jl7qvOoGOHWmpqa7jzwae4+Kp7GNCvF5eecwydN+rIawsWc8qPR/Phso85asRQTj/+4DXX999hK754/C+Z+cL8Cn6L9ct3Lvwb90+aSbfNuvD4388H4ORzr2XuqwsBeH/pcjbp3IlHbzyXT1bW8f2f38RTc14jl8tx8Q+OZL8hO1ay+m1CK40+9wRGS6ohadTdEhF3Sbpe0kCSrvErwKkAETFL0i3AbKAOOK3QyDOUMChKWhoRnUuVfzVb8UkdI//ztyxb/gm1NTnu/fOZPPDYbH559lH8+DdjeWz6ixz35b04/fiD+PmVd3PrfVO59b6pAOzSdytuuPQUB8QyO/Zf9+LbX/8ioy7465q0a39x8pr9H11+G107dwJg9Nh/AvDYzefzzrsfctT3ruCh0WdXzdRZpdDcrnFjIuIZYFAD6ccXuOYi4KJiy1h//0oVtmz5JwB0qK2hQ20NEcEO2/bgsekvAjBhynN8+YCBn7ruyEOHMOb+aWWtq8G+g3dgs64bNXgsIhj7wHSOPHQIAM+//BbDd98JgO6bd2GTzp14as5rZatrW9Xa9xRLpeRBUYlLJM2U9Kyko9P0npImpk+fz5Q0LB1qvy5z7vdLXb9KyeXExBvO4YVxFzNh8nNMm/Uqz720gMOG7wrAyIMG02vLzT513Vf/ZTBjxk0td3WtgMeemkePLbrQd9seAAzo14t7Jz5LXd0qXp2/iBnPvc78he9VuJaVp5yK2iqtHPcUjwAGArsB3YAnJU0EvgHcHxEXpfcHNkrP6xURAwDyN1TrS59bSp5d6lCdPfTVq4Phx11M186d+Nsl32bnvj35zoU3cPFZX+OH3zqMeyc+y8qV6976GNJ/O5Z/vJI58xZUqNbWkDHjpnLkIWufIPn3f9ubF15ZyAEn/Iptem7OHl/YntqamgrWsG1oC63AYpQjKO4H3JTe3Fwo6RFgd+BJ4Nr0VZ3bI2KGpJeAPpJ+B9wNjGsow4i4CrgKILdRj4LPHLV1HyxdzqRpczlo7134/d8e5MjT/wBA3217cMh+/dc594hDhjDmfrcS25K6ulXc9fDTPPzXH65Jq62t4ednHrnm8yEnX0qfbbpXonpthyeEWEeDv4mImAgMB+YD10s6ISLeI2lRTgBOA/5chvqV3Rabdl5zU37Djh3Yf4+dmPvKQrptlrR6JXHWyYfylzGT1lwjiZEHDWLMeN9PbEsmTHmeftttuc6tjo8+/oRly1cA8PDkOdTW5vh8n56NZbFeECAVt1VaOVqKE4FTJY0GNicJhGdL2g6YHxFXS9oYGCzpHuCTiBgjaR5wXRnqV3af69aVK35yPDW5HLmcGPvAdO6fNJNTj9mfb31tOAB3TZjBDf94Ys01+wzagTffXsKr8xdXqtrrtW+e/xf+OW0ui5cspf+XfsQ5pxzO8SP34bZx09YMsOQtevdDjjz9D+Ryomf3TbnypydWqNZtSdsYRCmGIkrT+8w/kqPkN/Er4DCSZ4j+JyL+LulE4GxgJbAUOAHoCvyFtS3YcyPi3k/nvlZuox7Rcaevl+Q7WGm89+TvK10Fa4Z99xzKtGlTWxTRNvzcjrHdib8r6twXfjViWqHX/EqtZC3F/DOKkUTds9Mte3w0MLqBSweXqk5mViFtpGtcDL/RYmYlJ5LH0KqBg6KZlYVbimZmGdUy0OKgaGal53uKZmZrCVXNhBgOimZWFm4pmpll+J6imVleFd1TrI5OvplVteTd55bPpyhpQ0lTJD0taZakn6bpl0h6Ll3Nb2xmyYLekpanUxTOkHRlU3V1S9HMyqKVWoorgAMjYmk6w9YkSfcC40leC66T9EvgXOC/0mvmRcSnZ2xuhFuKZlYWuZyK2gqJxNL0Y4d0i4gYFxF1afoTJKv2fbZ6ftYLzcyKpmZ1n7tJmprZTlknq2SG/hnA28D4iJhcr7STgexEMttLekrSI5KGNVVVd5/NrOTy8ykWaVGhWXLSCasHpvcNx0oaEBEzASSdT7Jq3w3p6QuAbSNisaQhwO2S+kfEB43l75aimZVBca3E5jy2ExFLSCakHgGQTkf4r8Bx6excRMSKiFic7k8D5gEF15t1UDSzsmiNmbcldc+MLHcCDgaekzSCZGDl3yLio3rn16T7fYB+wEuFynD32cxKT602dVhPYHQa6HLALRFxl6QXgY7A+LS1+UREjCKZ6f9CSXXAKmBURLxbqAAHRTMrufxzii0VEc8AgxpI36GR88cAY5pThoOimZWFX/MzM8uokpjooGhm5eGWoplZXhVNCOGgaGYll0wyWx1R0UHRzMoiVyVNRQdFMyuLKomJDopmVnqSB1rMzNZRJbcUGw+Kkn4HRGPHI+K7JamRmbVL7WGgZWrZamFm7ZpIRqCrQaNBMSJGZz9L2jgilpW+SmbWHlVJQ7HpqcMk7S1pNjAn/bybpCtKXjMzaz+KnEuxLQzGFDOf4v8ChwL5iRqfJpmOx8ysaK0xn2I5FDX6HBGv14vgq0pTHTNrj0T7enj7dUn7ACFpA+C7pF1pM7NiVcvoczHd51HAaUAvYD4wMP1sZlaUYrvORSxHsKGkKZKeljRL0k/T9M0ljZc0N/25WeaacyW9KOl5SYc2VdcmW4oRsQg4rslvbWZWQCt1n1cAB0bEUkkdgEmS7gWOAB6MiIslnQOcA/yXpF2AY4D+wFbAA5J2TFcEbLieTdVAUh9J/5D0jqS3Jd2RLgBjZlY0FbkVEoml6ccO6RbASCD/GOFo4Cvp/kjg5nRVv5eBF4E9CpVRTPf5RuAWkgVjtgJuBW4q4jozszWa8UhON0lTM9sp9fKpkTQDeBsYHxGTgS0jYgFA+rNHenov4PXM5W+kaY0qZqBFEXF95vPfJH2niOvMzID86HPRpy+KiKGNHUy7vgPTpU7HShrQRNGfyqJQ4YXefd483X047aPfnGZ2NHB3oUzNzNah1p9kNiKWSJoAjAAWSuoZEQsk9SRpRULSMtwmc9nWwJuF8i3UUpxGEgTz3+TUbH2AnxVffTNb37XG2yqSugMr04DYCTgY+CVwJ3AicHH68470kjuBGyVdRnL7rx8wpVAZhd593r7F38DMjGZ3nwvpCYyWVEMyJnJLRNwl6XHgFknfBF4DjgKIiFmSbgFmA3XAaYVGnqHIN1rSPvsuwIb5tIj462f4Qma2nmqNlmJEPAMMaiB9MXBQI9dcBFxUbBlNBkVJFwD7kwTFe4DDgEmAg6KZFa063mcp7pGcr5FE4Lci4iRgN6BjSWtlZu2KBDU5FbVVWjHd5+URsVpSnaSuJKM6fnjbzJqlLUwLVoxiguLU9Hmgq0lGpJfSxOiNmVl9VRITi3r3+f+lu1dKug/omt7sNDMrilD1Tx0maXChYxExvTRVMrN2p41MIFuMQi3FSwscC+DAVq7LZ/KFz2/DQ4/+b6WrYc2w2QH/XekqWDOseKHgCyBFq/p7ihFxQDkrYmbtl4Caag+KZmatqQ08bVMUB0UzKwsHRTOzVLLUQHVExWJm3pakf5f03+nnbSUVnLnWzKy+nIrbKq2Y1/yuAPYGjk0/fwj8oWQ1MrN2qT2t+7xnRAyW9BRARLyXLnVqZlYUAbVtIeIVoZiguDKduyxgzSSPq0taKzNrd6okJhYVFH8LjAV6SLqIZNacH5W0VmbWrkjt4DW/vIi4QdI0kunDBHwlIuaUvGZm1q60RkyUtA3JXK6fI+mxXhURv5H0d2Cn9LRNgSURMVBSb2AO8Hx67ImIGFWojGImmd0W+Aj4RzYtIl5r3tcxs/VZK40s1wE/iIjpkroA0ySNj4ij8ydIuhR4P3PNvIgYWGwBxXSf72btAlYbAtuTRN3+xRZiZus3QatMIJuu6Zxf3/lDSXNI1nGeDckjhMDXacHcDMV0n3fNfk5nzzm1kdPNzD6tec8gdpM0NfP5qoi46lNZJl3jQcDkTPIwYGFEzM2kbZ8+PfMB8KOIeLRQ4c1+oyVttu7e3OvMbP2m4ldpWRQRQwvmJXUGxgBnRMQHmUPHAjdlPi8Ato2IxZKGALdL6l/vmnUUc0/xzMzHHDAYeKep68zM8lpxiVMkdSAJiDdExG2Z9FrgCGBIPi0iVgAr0v1pkuYBOwJTaUQxLcUumf06knuMY5rxHczMWiUopvcMrwHmRMRl9Q4fDDwXEW9kzu8OvBsRqyT1AfoBLxUqo2BQTB/a7hwRZ3+WL2BmltdKE0LsCxwPPCtpRpp2XkTcAxzDul1ngOHAhZLqgFXAqIh4t1ABhZYjqI2IukLLEpiZFSNZ4rTl+UTEJBpZQjoi/qOBtDE0s2dbqKU4heT+4QxJdwK3Assyhd3W2IVmZvW1mzdagM2BxSTP/eSfVwzAQdHMitKaAy2lVigo9khHnmeyNhjmRUlrZWbtTpU0FAsGxRqgMw333x0UzawZRK745xQrqlBQXBARF5atJmbWbon20VKskq9gZm2eoLZKbioWCooHla0WZtautYuWYlMPOJqZNUd7eiTHzKzFqiQmOiiaWemJ4pYObQscFM2s9OTus5nZGskbLQ6KZmZrVEdIdFA0szKpkoaig6KZlYNaaz7FknNQNLOSq6bR52qpp5lVuZxU1FaIpG0kPSxpjqRZkr6Xpv9E0nxJM9Lt8Mw150p6UdLzkg5tqp5uKZpZ6anVliOoA36QriraBZgmaXx67PKI+PU6xUq7kCxT0B/YCnhA0o4RsaqxAtxSNLOSy3efi9kKiYgFETE93f8QmAP0KnDJSODmiFgRES8DLwJ7FCrDQdHMykJSURvQTdLUzHZKI/n1BgYBk9Ok70h6RtK1kjZL03oBr2cue4PCQdRB0czKQ0VuwKKIGJrZrvpUXlJnkgWpzkgXtv8j0BcYCCwALs0UW1/BSbJ9T9HMSk5ATSs9kiOpA0lAvCG/gF5ELMwcvxq4K/34BrBN5vKtgTcL5e+WopmVhVTcVjgPCbgGmBMRl2XSe2ZO+yrJ2lIAdwLHSOooaXugH8lKpY1yS9HMykCodV702xc4HnhW0ow07TzgWEkDSbrGrwCnAkTELEm3ALNJRq5PKzTyDA6KZlYmrdF7johJNHyf8J4C11wEXFRsGQ6KZlZyySM5fs3PzCxRxP3CtsJB0czKwvMpmpmlkklmK12L4jgomllZtNLoc8k5KJpZWVRJ79lBsRLO/PmNPPDYbLpt1pmHrj8HgFlz53POr2/ho+WfsPXnNuf3FxxPl403BOB314/n5rsmk8uJn51xBPvvuXMlq79e6tihlrt/czIdN6ilpibHnY/M4uLrHmZA389x2ZlfZsMNaqlbtZqz/vcupj83H4D+fbbksjP/jS4bdyRWBweO+hMrVtZV+JtUjluKRZJ0D/CNiFhS6bqUy9cP35OTjhzG9/7nhjVpZ//yZn582kj2HrQDN9/1BH+88SF++O3DeeHlt7jjgad46PpzWLjofY454woevel8amr8MlI5rVhZx8gzr2PZx59QW5Pj3t99iwcmz+Xckw7kV6Mn8MCUufzLnv346amH8OXv/4WaXI4/nXcko34xhpnzFrJZ106sXFXwmeF2rZruKVb8/6yIOHx9CogAew3sy6ZdN1onbd5rb7PXwL4ADNt9J+555GkA7p/0LCMPHkTHDWrZdqst6L11N56a82rZ62yw7ONPAOhQW0OHmhxB8vpEl407AtB14w15a/GHABy4e19mvbSQmfOSV3Lf+2A5q1cXnIegfStygtm2MEJd8paipB8CH0fEbyVdDuwWEQdKOgg4CdgPGAp0Bu4FJgH7APOBkRGxvNR1bAt26tOTcZNmcuiwXbnr4Rm8uTD5d+Ktd95ncP/ea87r2X1T3nrn/QrVcv2Wy4kJfxrF9r0255rbpzBtzhuc9/t7GPOrE/jZqEORxIjTrwag79bdiAj+71cn0G2Tjbjt4Zn89uZJFf4GlVX5cFeccrQUJwLD0v2hQOd0lov9gEfrndsP+ENE9AeWAEc2lKGkU/JzrS1etKhE1S6vy849lutum8SIk3/Nso9W0KFDDQDRQOOiWhYAam9Wrw6Gf/uP9D/qUgZ/fmt27t2Dk0fuwXlX3MeAoy/l/Cvu5bdnfwWA2poce+26Haf8z/9x2Hev4Uv77czwwX0q/A0qJ7/uczW0FMsRFKcBQ9Kpw1cAj5MEx2F8Oii+HBEzMtf1bijDiLgqP9faFt26labWZbbDdlty0+X/yX3XnsXIgwfTu1fyvXr22IQ3335vzXkL3lnClt26VqqaBnyw7GMmzXiZg/box7GHDOQfE2cDcPuEWQz+fDJ/6ZvvvM8/n36Fdz/4iOUrVjJ+8gvs1q9noWzbvWbMp1hRJQ+KEbGSZNaKk4DHSALhASQTQs6pd/qKzP4q2sBAULksei+5F7V69Wp+M3ocx4/cB4BD9h3AHQ88xYpP6njtzcW8/PoiBu28XSWrul7aYpON6Jo+DbDhBrXsP6Qvc197hwWLP2Tf3XoDMHxwH16a/y4ADz75Iv37bEmnjh2oyeXYd7fePP/qO5WqfttQJVGxXEFnInAWcDLwLHAZMC0iYn3sCv6/C0bz+Ix5vLtkKUO+egFnffMwln20gutuS+45Hf7FL3D0l/YEknuNXz5wIAf8+y+oqclx0ZlHeuS5Aj63RReuOOcIanIilxNjJ8zi/ide4P2lH/OL0w+ntibHx5/UccaldwDw/tKPueLWx3jwylMhgvGT5zLuiRcq/C0qqy10jYuhaOimVWsXkgyq3AdsGhHLJL0AXBkRl0l6hbUDLXdFxID0mrOAzhHxk0J5Dxw8JB56dHKhU6yN6TXiwkpXwZphxYw/s/rDN1sU0XbedVD89Y4JRZ27R99Np0XE0JaU1xJlaSlGxINAh8znHTP7vdPdRcCATPo6SxWaWZWrjoZi5Z9TNLP2L7ldWNx/BfORtpH0sKQ5kmZJ+l6afomk59LV/MZK2jRN7y1puaQZ6XZlU3V1UDSz0ityfZYibjvWAT+IiJ2BvYDT0gXvxwMDIuILwAvAuZlr5kXEwHQb1VQBDopmVhatMfgcEQsiYnq6/yHJEyy9ImJcRORfLH+CZNW+z8RB0czKoOGF7xvagG75lzPS7ZQGc5R6A4OA+iOtJ5O8HZe3vaSnJD0iaRhNWG+eAzSzymrGEzmLmhp9ltSZZO3nMyLig0z6+SRd7PxsKwuAbSNisaQhwO2S+mevqc8tRTMruWK7zsXEzfQ14THADRFxWyb9ROBfgeMifdYwIlZExOJ0fxowD9jx07mu5ZaimZVHKzySo6R/fQ0wJyIuy6SPAP4L+GJEfJRJ7w68GxGrJPUhmV/hpUJlOCiaWVm00iSz+wLHA89Kys+TcB7wW6AjMD69L/lEOtI8HLhQUh3Jq8OjIuLdQgU4KJpZWbTGW34RMYmG25z3NHL+GJKudtEcFM2s9Lzus5nZurxGi5lZSrilaGa2jiqJiQ6KZlYmVRIVHRTNrCyqZZJZB0UzK4vqCIkOimZWLlUSFR0Uzazk8pPMVgMHRTMrPT+8bWa2riqJiQ6KZlYOayaQbfMcFM2sLKokJjoomlnpFTuBbFvgoGhm5VElUdFB0czKoloeyfEaLWZWFq2x7rOkbSQ9LGmOpFmSvpemby5pvKS56c/NMtecK+lFSc9LOrSpejoomlnpCXJFbk2oA34QETsDewGnSdoFOAd4MCL6AQ+mn0mPHQP0B0YAV0iqKVSAg6KZlUnL1/OLiAURMT3d/xCYA/QCRgKj09NGA19J90cCN6er+r0MvAjsUagMB0UzK7n8JLNFdp+7SZqa2U5pME+pNzAImAxsGRELIAmcQI/0tF7A65nL3kjTGuWBFjMri2YMsyyKiKEF85I6kyxIdUZEfFDgwfCGDkShvN1SNLOyaI2BliQfdSAJiDdExG1p8kJJPdPjPYG30/Q3gG0yl28NvFkofwdFMysLSUVtTeQh4BpgTkRcljl0J3Biun8icEcm/RhJHSVtD/QDphQqw91nMyuLVnpKcV/geOBZSTPStPOAi4FbJH0TeA04CiAiZkm6BZhNMnJ9WkSsKlSAg6KZlVyxXeOmRMQkGo+vBzVyzUXARcWW4aBoZmVRLW+0OCiaWXlUR0x0UDSz8qiSmOigaGblIC9xamaWl3+jpRr4OUUzswy3FM2sLKqlpeigaGZl4UdyzMzyvO6zmdla1TTQ4qBoZmXh7rOZWYZbimZmGVUSEx0UzaxMqiQqOiiaWckJquY1P0UUXK6gzZP0DvBqpetRAt2ARZWuhDVLe/2bbRcR3VuSgaT7SH4/xVgUESNaUl5LVH1QbK8kTW1q8R5rW/w3ax/87rOZWYaDoplZhoNi23VVpStgzea/WTvge4pmZhluKZqZZTgompllOChWgKSlla6DtS5J90jatNL1sJbzPcUKkLQ0IjpXuh5m9mluKVaQEpdIminpWUlHp+k9JU2UNCM9NkxSjaTrMud+v9L1X59I+qGk76b7l0t6KN0/SNLfJL0iqZuk3pLmSLpa0ixJ4yR1qmztrTkcFCvrCGAgsBtwMHCJpJ7AN4D7IyJ/bEZ6Xq+IGBARuwJ/qVCd11cTgWHp/lCgs6QOwH7Ao/XO7Qf8ISL6A0uAI8tWS2sxB8XK2g+4KSJWRcRC4BFgd+BJ4CRJPwF2jYgPgZeAPpJ+J2kE8EGlKr2emgYMkdQFWAE8ThIch/HpoPhyRMzIXNe7XJW0lnNQrKwGpw2JiInAcGA+cL2kEyLiPZJW4wTgNODP5aqkQUSsBF4BTgIeIwmEBwB9gTn1Tl+R2V+FZ6OqKg6KlTURODq9X9idJBBOkbQd8HZEXA1cAwyW1A3IRcQY4MfA4IrVev01ETgr/fkoMAqYER6tbFf8L1hljQX2Bp4GAvhhRLwl6UTgbEkrgaXACUAv4C+S8v+QnVuJCq/nHgXOBx6PiGWSPubTXWercn4kx8wsw91nM7MMB0UzswwHRTOzDAdFM7MMB0UzswwHxXZO0qrMO9S3StqoBXldJ+lr6f6fJe1S4Nz9Je3zGcp4JX0ms6j0euc0a/YhST+RdFZz62jtm4Ni+7c8IgZGxADgE5IHjteQVPNZMo2Ib0XE7AKn7A80OyiaVZqD4vrlUWCHtBX3sKQbgWfTN2oukfSkpGcknQprZvH5vaTZku4GeuQzkjRB0tB0f4Sk6ZKelvSgpN4kwff7aSt1mKTuksakZTwpad/02i3SmWSekvQnGnn1MUvS7ZKmpbPQnFLv2KVpXR5M3xJCUl9J96XXPCrp863xy7T2yW+0rCck1QKHAfelSXsAAyLi5TSwvB8Ru0vqCPxT0jhgELATsCuwJTAbuLZevt2Bq4HhaV6bR8S7kq4ElkbEr9PzbgQuj4hJkrYF7gd2Bi4AJkXEhZK+BKwT5BpxclpGJ+BJSWMiYjGwMTA9In4g6b/TvL9DsqDUqIiYKzD0GXQAAAG9SURBVGlP4ArgwM/wa7T1gINi+9dJUn7GlkdJ3qXeB5gSES+n6YcAX8jfLwQ2IZn+ajjpLD7Am/k5BOvZC5iYzysi3m2kHgcDu0hrGoJd0xlnhpNMoUZE3C3pvSK+03clfTXd3yat62JgNfD3NP1vwG2SOqff99ZM2R2LKMPWUw6K7d/ydF7GNdLgsCybBJweEffXO+9wkneyC1ER50Byq2bviFjeQF2KftdU0v4kAXbviPhI0gRgw0ZOj7TcJfV/B2aN8T1Fg6Qr+5/ppKlI2lHSxiSzwRyT3nPsSTJVVn2PA1+UtH167eZp+odAl8x540i6sqTn5YPUROC4NO0wYLMm6roJ8F4aED9P0lLNywH51u43SLrlHwAvSzoqLUOSdmuiDFuPOSgaJHMzzgamS5oJ/ImkFzEWmAs8C/yRZBLcdUTEOyT3AW+T9DRru6//AL6aH2gBvgsMTQdyZrN2FPynwHBJ00m68a81Udf7gFpJzwA/A57IHFsG9Jc0jeSe4YVp+nHAN9P6zQJGFvE7sfWUZ8kxM8twS9HMLMNB0cwsw0HRzCzDQdHMLMNB0cwsw0HRzCzDQdHMLOP/A3MQxPPYxdEuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues, display_labels=[\"loss\", \"win\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Deep Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=10, activation='relu', input_dim=6))\n",
    "deep_model.add(Dense(units=8, activation='relu'))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=4, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3225 samples\n",
      "Epoch 1/100\n",
      "3225/3225 - 2s - loss: 0.6558 - accuracy: 0.6068\n",
      "Epoch 2/100\n",
      "3225/3225 - 0s - loss: 0.6330 - accuracy: 0.6639\n",
      "Epoch 3/100\n",
      "3225/3225 - 0s - loss: 0.6201 - accuracy: 0.6738\n",
      "Epoch 4/100\n",
      "3225/3225 - 0s - loss: 0.6133 - accuracy: 0.6722\n",
      "Epoch 5/100\n",
      "3225/3225 - 0s - loss: 0.6102 - accuracy: 0.6707\n",
      "Epoch 6/100\n",
      "3225/3225 - 0s - loss: 0.6071 - accuracy: 0.6741\n",
      "Epoch 7/100\n",
      "3225/3225 - 0s - loss: 0.6048 - accuracy: 0.6738\n",
      "Epoch 8/100\n",
      "3225/3225 - 0s - loss: 0.6042 - accuracy: 0.6679\n",
      "Epoch 9/100\n",
      "3225/3225 - 0s - loss: 0.6020 - accuracy: 0.6713\n",
      "Epoch 10/100\n",
      "3225/3225 - 0s - loss: 0.6014 - accuracy: 0.6732\n",
      "Epoch 11/100\n",
      "3225/3225 - 0s - loss: 0.6004 - accuracy: 0.6716\n",
      "Epoch 12/100\n",
      "3225/3225 - 0s - loss: 0.5988 - accuracy: 0.6744\n",
      "Epoch 13/100\n",
      "3225/3225 - 0s - loss: 0.5987 - accuracy: 0.6753\n",
      "Epoch 14/100\n",
      "3225/3225 - 0s - loss: 0.5983 - accuracy: 0.6757\n",
      "Epoch 15/100\n",
      "3225/3225 - 0s - loss: 0.5973 - accuracy: 0.6750\n",
      "Epoch 16/100\n",
      "3225/3225 - 0s - loss: 0.5973 - accuracy: 0.6732\n",
      "Epoch 17/100\n",
      "3225/3225 - 0s - loss: 0.5967 - accuracy: 0.6763\n",
      "Epoch 18/100\n",
      "3225/3225 - 0s - loss: 0.5959 - accuracy: 0.6744\n",
      "Epoch 19/100\n",
      "3225/3225 - 0s - loss: 0.5957 - accuracy: 0.6738\n",
      "Epoch 20/100\n",
      "3225/3225 - 0s - loss: 0.5956 - accuracy: 0.6722\n",
      "Epoch 21/100\n",
      "3225/3225 - 0s - loss: 0.5947 - accuracy: 0.6753\n",
      "Epoch 22/100\n",
      "3225/3225 - 0s - loss: 0.5943 - accuracy: 0.6750\n",
      "Epoch 23/100\n",
      "3225/3225 - 0s - loss: 0.5944 - accuracy: 0.6760\n",
      "Epoch 24/100\n",
      "3225/3225 - 0s - loss: 0.5941 - accuracy: 0.6732\n",
      "Epoch 25/100\n",
      "3225/3225 - 0s - loss: 0.5930 - accuracy: 0.6772\n",
      "Epoch 26/100\n",
      "3225/3225 - 0s - loss: 0.5933 - accuracy: 0.6747\n",
      "Epoch 27/100\n",
      "3225/3225 - 0s - loss: 0.5923 - accuracy: 0.6735\n",
      "Epoch 28/100\n",
      "3225/3225 - 0s - loss: 0.5923 - accuracy: 0.6757\n",
      "Epoch 29/100\n",
      "3225/3225 - 0s - loss: 0.5921 - accuracy: 0.6729\n",
      "Epoch 30/100\n",
      "3225/3225 - 0s - loss: 0.5918 - accuracy: 0.6794\n",
      "Epoch 31/100\n",
      "3225/3225 - 0s - loss: 0.5912 - accuracy: 0.6753\n",
      "Epoch 32/100\n",
      "3225/3225 - 0s - loss: 0.5911 - accuracy: 0.6778\n",
      "Epoch 33/100\n",
      "3225/3225 - 0s - loss: 0.5911 - accuracy: 0.6729\n",
      "Epoch 34/100\n",
      "3225/3225 - 0s - loss: 0.5899 - accuracy: 0.6763\n",
      "Epoch 35/100\n",
      "3225/3225 - 0s - loss: 0.5898 - accuracy: 0.6775\n",
      "Epoch 36/100\n",
      "3225/3225 - 0s - loss: 0.5901 - accuracy: 0.6753\n",
      "Epoch 37/100\n",
      "3225/3225 - 0s - loss: 0.5897 - accuracy: 0.6763\n",
      "Epoch 38/100\n",
      "3225/3225 - 0s - loss: 0.5893 - accuracy: 0.6778\n",
      "Epoch 39/100\n",
      "3225/3225 - 0s - loss: 0.5882 - accuracy: 0.6816\n",
      "Epoch 40/100\n",
      "3225/3225 - 0s - loss: 0.5882 - accuracy: 0.6791\n",
      "Epoch 41/100\n",
      "3225/3225 - 0s - loss: 0.5885 - accuracy: 0.6803\n",
      "Epoch 42/100\n",
      "3225/3225 - 0s - loss: 0.5878 - accuracy: 0.6763\n",
      "Epoch 43/100\n",
      "3225/3225 - 0s - loss: 0.5878 - accuracy: 0.6775\n",
      "Epoch 44/100\n",
      "3225/3225 - 0s - loss: 0.5873 - accuracy: 0.6778\n",
      "Epoch 45/100\n",
      "3225/3225 - 0s - loss: 0.5870 - accuracy: 0.6766\n",
      "Epoch 46/100\n",
      "3225/3225 - 0s - loss: 0.5867 - accuracy: 0.6797\n",
      "Epoch 47/100\n",
      "3225/3225 - 1s - loss: 0.5865 - accuracy: 0.6800\n",
      "Epoch 48/100\n",
      "3225/3225 - 1s - loss: 0.5859 - accuracy: 0.6825\n",
      "Epoch 49/100\n",
      "3225/3225 - 0s - loss: 0.5864 - accuracy: 0.6806\n",
      "Epoch 50/100\n",
      "3225/3225 - 1s - loss: 0.5859 - accuracy: 0.6812\n",
      "Epoch 51/100\n",
      "3225/3225 - 0s - loss: 0.5850 - accuracy: 0.6825\n",
      "Epoch 52/100\n",
      "3225/3225 - 1s - loss: 0.5850 - accuracy: 0.6816\n",
      "Epoch 53/100\n",
      "3225/3225 - 0s - loss: 0.5855 - accuracy: 0.6825\n",
      "Epoch 54/100\n",
      "3225/3225 - 0s - loss: 0.5845 - accuracy: 0.6816\n",
      "Epoch 55/100\n",
      "3225/3225 - 0s - loss: 0.5848 - accuracy: 0.6850\n",
      "Epoch 56/100\n",
      "3225/3225 - 0s - loss: 0.5843 - accuracy: 0.6834\n",
      "Epoch 57/100\n",
      "3225/3225 - 0s - loss: 0.5840 - accuracy: 0.6828\n",
      "Epoch 58/100\n",
      "3225/3225 - 0s - loss: 0.5836 - accuracy: 0.6828\n",
      "Epoch 59/100\n",
      "3225/3225 - 0s - loss: 0.5835 - accuracy: 0.6819\n",
      "Epoch 60/100\n",
      "3225/3225 - 0s - loss: 0.5832 - accuracy: 0.6822\n",
      "Epoch 61/100\n",
      "3225/3225 - 0s - loss: 0.5829 - accuracy: 0.6847\n",
      "Epoch 62/100\n",
      "3225/3225 - 0s - loss: 0.5830 - accuracy: 0.6840\n",
      "Epoch 63/100\n",
      "3225/3225 - 0s - loss: 0.5827 - accuracy: 0.6862\n",
      "Epoch 64/100\n",
      "3225/3225 - 0s - loss: 0.5821 - accuracy: 0.6853\n",
      "Epoch 65/100\n",
      "3225/3225 - 0s - loss: 0.5817 - accuracy: 0.6871\n",
      "Epoch 66/100\n",
      "3225/3225 - 0s - loss: 0.5817 - accuracy: 0.6868\n",
      "Epoch 67/100\n",
      "3225/3225 - 0s - loss: 0.5818 - accuracy: 0.6881\n",
      "Epoch 68/100\n",
      "3225/3225 - 0s - loss: 0.5817 - accuracy: 0.6843\n",
      "Epoch 69/100\n",
      "3225/3225 - 0s - loss: 0.5807 - accuracy: 0.6850\n",
      "Epoch 70/100\n",
      "3225/3225 - 0s - loss: 0.5811 - accuracy: 0.6871\n",
      "Epoch 71/100\n",
      "3225/3225 - 0s - loss: 0.5808 - accuracy: 0.6899\n",
      "Epoch 72/100\n",
      "3225/3225 - 0s - loss: 0.5810 - accuracy: 0.6896\n",
      "Epoch 73/100\n",
      "3225/3225 - 0s - loss: 0.5800 - accuracy: 0.6915\n",
      "Epoch 74/100\n",
      "3225/3225 - 0s - loss: 0.5799 - accuracy: 0.6896\n",
      "Epoch 75/100\n",
      "3225/3225 - 0s - loss: 0.5799 - accuracy: 0.6878\n",
      "Epoch 76/100\n",
      "3225/3225 - 0s - loss: 0.5797 - accuracy: 0.6899\n",
      "Epoch 77/100\n",
      "3225/3225 - 0s - loss: 0.5797 - accuracy: 0.6918\n",
      "Epoch 78/100\n",
      "3225/3225 - 0s - loss: 0.5792 - accuracy: 0.6905\n",
      "Epoch 79/100\n",
      "3225/3225 - 0s - loss: 0.5795 - accuracy: 0.6902\n",
      "Epoch 80/100\n",
      "3225/3225 - 0s - loss: 0.5791 - accuracy: 0.6927\n",
      "Epoch 81/100\n",
      "3225/3225 - 0s - loss: 0.5796 - accuracy: 0.6893\n",
      "Epoch 82/100\n",
      "3225/3225 - 0s - loss: 0.5790 - accuracy: 0.6921\n",
      "Epoch 83/100\n",
      "3225/3225 - 0s - loss: 0.5785 - accuracy: 0.6940\n",
      "Epoch 84/100\n",
      "3225/3225 - 0s - loss: 0.5779 - accuracy: 0.6896\n",
      "Epoch 85/100\n",
      "3225/3225 - 0s - loss: 0.5784 - accuracy: 0.6924\n",
      "Epoch 86/100\n",
      "3225/3225 - 0s - loss: 0.5775 - accuracy: 0.6915\n",
      "Epoch 87/100\n",
      "3225/3225 - 0s - loss: 0.5780 - accuracy: 0.6918\n",
      "Epoch 88/100\n",
      "3225/3225 - 0s - loss: 0.5781 - accuracy: 0.6899\n",
      "Epoch 89/100\n",
      "3225/3225 - 0s - loss: 0.5773 - accuracy: 0.6936\n",
      "Epoch 90/100\n",
      "3225/3225 - 0s - loss: 0.5777 - accuracy: 0.6952\n",
      "Epoch 91/100\n",
      "3225/3225 - 0s - loss: 0.5767 - accuracy: 0.6949\n",
      "Epoch 92/100\n",
      "3225/3225 - 0s - loss: 0.5769 - accuracy: 0.6955\n",
      "Epoch 93/100\n",
      "3225/3225 - 0s - loss: 0.5778 - accuracy: 0.6943\n",
      "Epoch 94/100\n",
      "3225/3225 - 0s - loss: 0.5767 - accuracy: 0.6983\n",
      "Epoch 95/100\n",
      "3225/3225 - 0s - loss: 0.5760 - accuracy: 0.6974\n",
      "Epoch 96/100\n",
      "3225/3225 - 0s - loss: 0.5768 - accuracy: 0.6933\n",
      "Epoch 97/100\n",
      "3225/3225 - 0s - loss: 0.5765 - accuracy: 0.6983\n",
      "Epoch 98/100\n",
      "3225/3225 - 0s - loss: 0.5759 - accuracy: 0.6933\n",
      "Epoch 99/100\n",
      "3225/3225 - 0s - loss: 0.5765 - accuracy: 0.6940\n",
      "Epoch 100/100\n",
      "3225/3225 - 0s - loss: 0.5756 - accuracy: 0.6958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4259b668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_model.fit(\n",
    "#     X_train_scaled,\n",
    "#     y_train_categorical,\n",
    "#     epochs=100,\n",
    "#     shuffle=True,\n",
    "#     verbose=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383/1 - 1s - loss: 0.5400 - accuracy: 0.6725\n",
      "Deep Neural Network - Loss: 0.6010508212548447, Accuracy: 0.6724511981010437\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"Win\"]\n",
    "target_names = [\"loss\", \"win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>net_points</th>\n",
       "      <th>net_yard</th>\n",
       "      <th>net_turn</th>\n",
       "      <th>weekly_rank</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>-14</td>\n",
       "      <td>-147</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-67</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>-2</td>\n",
       "      <td>25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>159</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>144</td>\n",
       "      <td>-4</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-286</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>-27</td>\n",
       "      <td>-144</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-78</td>\n",
       "      <td>-4</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>-14</td>\n",
       "      <td>-59</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>-31</td>\n",
       "      <td>-159</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-40</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-68</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-78</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-37</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-127</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    home  net_points  net_yard  net_turn  weekly_rank  spread\n",
       "0      1           0         0         0            2    -5.5\n",
       "1      0           0         0         0            6     5.5\n",
       "2      1           0         0         0           17    -1.0\n",
       "3      0           0         0         0           15     1.0\n",
       "4      1           0         0         0           27    -3.0\n",
       "5      0           0         0         0           31     3.0\n",
       "6      1           0         0         0           19    -3.0\n",
       "7      0           0         0         0           20     3.0\n",
       "8      1           0         0         0           21     3.0\n",
       "9      0           0         0         0            9    -3.0\n",
       "10     1           0         0         0           24     3.0\n",
       "11     0           0         0         0            7    -3.0\n",
       "12     1           0         0         0           32     4.5\n",
       "13     0           0         0         0           13    -4.5\n",
       "14     1           0         0         0           14     6.5\n",
       "15     0           0         0         0            1    -6.5\n",
       "16     1           0         0         0           12    -7.0\n",
       "17     0           0         0         0           22     7.0\n",
       "18     1           0         0         0           29    -3.0\n",
       "19     0           0         0         0           26     3.0\n",
       "20     1           0         0         0            3    -6.0\n",
       "21     0           0         0         0            4     6.0\n",
       "22     1           0         0         0           10    -6.0\n",
       "23     0           0         0         0           28     6.0\n",
       "24     1           0         0         0           30    -2.0\n",
       "25     0           0         0         0           25     2.0\n",
       "26     1           0         0         0            8    -6.5\n",
       "27     0           0         0         0           18     6.5\n",
       "28     1           0         0         0           11    -2.5\n",
       "29     0           0         0         0            5     2.5\n",
       "30     1           0         0         0           16    -3.0\n",
       "31     0           0         0         0           23     3.0\n",
       "32     1         -14      -147         0           20    -3.0\n",
       "33     0           3       -67        -1           15     3.0\n",
       "34     1          14       147         0           12    -6.0\n",
       "35     0          17        96        -2           25     6.0\n",
       "36     1           3        78         1           14     7.0\n",
       "37     0          31       159        -2            2    -7.0\n",
       "38     1          27       144        -4            9   -10.0\n",
       "39     0          -1      -286         0           26    10.0\n",
       "40     1         -27      -144         4           32     7.0\n",
       "41     0           7       -78        -4            6    -7.0\n",
       "42     1         -14       -59         1           28     4.0\n",
       "43     0         -31      -159         2           11    -4.0\n",
       "44     1         -10       -40        -1           22    -2.0\n",
       "45     0           3       -68        -1           17     2.0\n",
       "46     1          -3       -78        -1           16   -10.0\n",
       "47     0         -21       -37         1           31    10.0\n",
       "48     1          -3      -127        -1           27     3.5\n",
       "49     0          10        40         1            5    -3.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=['Win', 'WinSpread'],axis=1)\n",
    "feature_names = data.columns\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6883680555555556"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005208333333334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, criterion='entropy')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2855419994646104, 'spread'),\n",
       " (0.20935694375333036, 'net_yard'),\n",
       " (0.19346595037864367, 'net_points'),\n",
       " (0.1545549848784212, 'weekly_rank'),\n",
       " (0.13116094775745768, 'net_turn'),\n",
       " (0.025919173767536805, 'home')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(rf, X_test, y_test, cmap=plt.cm.Blues, display_labels=[\"loss\", \"win\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.69      0.72      0.70       576\n",
      "         win       0.71      0.67      0.69       576\n",
      "\n",
      "    accuracy                           0.70      1152\n",
      "   macro avg       0.70      0.70      0.70      1152\n",
      "weighted avg       0.70      0.70      0.70      1152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions, target_names=[\"loss\", \"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6961805555555556"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   49.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400,\n",
       "                                          450]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Support vector machine linear classifier\n",
    "model = SVC()\n",
    "\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "# 'C': regularization parameter: lower C means stronger regularization (\"softer\" margins)\n",
    "# 'rbf': \"Radial Basis Function\" kernel is a Gaussian kernel (for non-linear boundaries)\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100,150,200,250,300,350,400,450],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "# Note: verbose doesn't work in parallel\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
