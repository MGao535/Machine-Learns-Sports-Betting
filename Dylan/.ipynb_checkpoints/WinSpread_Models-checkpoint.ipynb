{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models target value = ' Win Spread ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>net_points</th>\n",
       "      <th>net_yard</th>\n",
       "      <th>net_turn</th>\n",
       "      <th>weekly_rank</th>\n",
       "      <th>spread</th>\n",
       "      <th>Win</th>\n",
       "      <th>WinSpread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1268</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>-104</td>\n",
       "      <td>-15</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0</td>\n",
       "      <td>-34</td>\n",
       "      <td>-325</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-302</td>\n",
       "      <td>-5</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>-260</td>\n",
       "      <td>-5</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home  net_points  net_yard  net_turn  weekly_rank  spread  Win  \\\n",
       "0        1           0         0         0            2    -5.5  1.0   \n",
       "1        0           0         0         0            6     5.5  0.0   \n",
       "2        1           0         0         0           17    -1.0  0.0   \n",
       "3        0           0         0         0           15     1.0  1.0   \n",
       "4        1           0         0         0           27    -3.0  1.0   \n",
       "...    ...         ...       ...       ...          ...     ...  ...   \n",
       "4603     0         116      1268        -4           10     6.0  1.0   \n",
       "4604     1         112      -104       -15            7    -6.5  1.0   \n",
       "4605     0         -34      -325         0           13     6.5  0.0   \n",
       "4606     1          52      -302        -5            8    -3.0  0.0   \n",
       "4607     0          56      -260        -5           11     3.0  1.0   \n",
       "\n",
       "      WinSpread  \n",
       "0           1.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           1.0  \n",
       "...         ...  \n",
       "4603        1.0  \n",
       "4604        0.0  \n",
       "4605        1.0  \n",
       "4606        0.0  \n",
       "4607        1.0  \n",
       "\n",
       "[4608 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"new_final_df.csv\")\n",
    "cols = [0]\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "df.loc[df.Win == 0.5,'Win'] = 0\n",
    "df.loc[df.WinSpread == 0.5,'WinSpread'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Win', 'WinSpread'],axis=1)\n",
    "y = df['WinSpread']\n",
    "y = y.astype('int')\n",
    "\n",
    "#Split to test and train \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.511\n",
      "Test set accuracy: 0.502\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "score = logreg.score(X_train, y_train)\n",
    "score2 = logreg.score(X_test, y_test)\n",
    "\n",
    "print (\"Training set accuracy:\", '%.3f'%(score))\n",
    "print (\"Test set accuracy:\", '%.3f'%(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [0 0 0 0 0 0 1 0 0 1]\n",
      "First 10 Actual labels: [0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -0.8418821854250693\n",
      "Mean Squared Error: 0.4600694444444444\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metric\n",
    "r2 = metric.r2_score(y_test, predictions)\n",
    "mse = metric.mean_squared_error(y_test, predictions)\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xVVf3/8dd7BgQVCBQhBBRCTUESESVFyGvi5ZupZdhFU3+pfbH8ekmlb1+vkVaaPvKWWipmSfSwlNC8JoF5QUBQAS8UKiCBKKB4QWb4/P7Ye2AzMoc9MeecOcP7+Xjsx5yzzt5rrzM8eM/al7W2IgIzM0tUlbsBZmbNiUPRzCzDoWhmluFQNDPLcCiamWW0KncDNpVabRnaon25m2GN8Llde5a7CdYI8994nbeXLtWm1FHdYceImg9zrRsfvvVQRAzflP1tisoPxS3a0+azx5e7GdYIj066ttxNsEY4ZNjgTa4jaj7M/f/0oxk3dN7kHW6Cig9FM6sEAlXG2TqHopkVn4Cq6nK3IheHopmVhjbptGTJOBTNrAQq5/C5MlppZpVPyrfkqkrVkp6TNCF9f4mkhZJmpMsRmXVHSZor6WVJh22sbvcUzaz4RFP3FM8C5gAdMmXXRMRV6+1W6guMAPoB2wOPStolImobqtg9RTMrgZy9xBw9RUk9gCOBX+fY8dHA2IhYFRHzgLnAPoU2cCiaWWlUVedboLOkqZnltHo1XQucD6ypV36mpOcl3SapU1rWHZifWWdBWtZwM//zb2hmlld6oSXPAksjYlBmuWVtLdJRwJKImFZvBzcBfYABwCLg6nU7/oSCk8j6nKKZFZ9oqltyhgBfSi+ktAU6SLorIr65dlfSrcCE9O0CIDuutAfwZqEduKdoZqWRv6fYoIgYFRE9IqIXyQWUv0XENyV1y6x2DPBi+no8MEJSG0m9gZ2BKYX24Z6imZVA0e9T/JmkASSHxq8BpwNExCxJ44DZQA0wstCVZ3AomlkpCKhu2mF+ETERmJi+/laB9UYDo/PW61A0s9LwMD8zszqVM8zPoWhmpeGeoplZhnuKZmapRkz2UG4ORTMrDU8ya2ZWxxdazMzW58NnM7NU08+nWDQORTMrAR8+m5mtzxdazMwyfE7RzCwlHz6bma3PPUUzs3XkUDQzSyRPI3AompklJFTlUDQzW8s9RTOzDIeimVmGQ9HMrI7Y8GPpmyGHopkVnVDF9BQr4xZzM6t4VVVVuZY8JFVLek7ShPT9NpIekfRq+rNTZt1RkuZKelnSYRtt53/8Dc3MGkFSriWns4A5mfcXAo9FxM7AY+l7JPUFRgD9gOHAjZIKzkzhUDSz4lMjlo1VJfUAjgR+nSk+GhiTvh4DfDlTPjYiVkXEPGAusE+h+h2KZlYSjegpdpY0NbOcVq+qa4HzgTWZsq4RsQgg/dklLe8OzM+styAta5AvtJhZ0TXyQsvSiBi0wXqko4AlETFN0gG5dv1JUWgDh6KZlUQTDfMbAnxJ0hFAW6CDpLuAxZK6RcQiSd2AJen6C4Ceme17AG8W2oEPn82s+NQ0F1oiYlRE9IiIXiQXUP4WEd8ExgMnpaudBNyXvh4PjJDURlJvYGdgSqF9uKdoZiVR5PsUrwTGSToVeAP4KkBEzJI0DpgN1AAjI6K2UEUORTMriaYOxYiYCExMX78NHNzAeqOB0XnrdSiaWdFV0ogWh6KZlUZlZKJD0cxKQOQewlduDkUzKwkfPpuZZVVGJjoUy6mqSjx+5/ksWrKCEef8CoDvHP8FvnP8MGpq1/DIEy9y8XX30bPbNjwz7kfMfSO5H3XqC69xzpVjy9n0zc65V/yex56czbad2vHYnRcC8OMb7uPRJ2fRulU1O3bvzNWjTuBT7bdidU0t5/90LC+8soDa2lqOO2xvzvzWoWX+BuW32fcUJa2MiHbFqr8lOGPEgbwybzHtt24LwP577cwRX+jP/idcwcera+jcad2v77WFSxn2jSvL1dTN3lcPH8y3jx3K/4z+3dqyoXt/lgtPP4pWrar5yU3jueGuR/nhd7/EhMdnsOrjGh4dcwEffvQxB33rCo4+ZCA9u21bxm9QXo2cAaesKuPMZwu0fZeOfHH/ftx535Nry045bijXjnmEj1fXALB02cpyNc/q+fyAPnTssNV6ZV/YZ1datUpmodqzXy8WvbUCSJ75/uFHH1NTU8tHq1bTulUr2qV/+DZnTTx1WNEUPRSV+LmkFyW9IOlraXk3SZMkzUg/G5pOHHlHZt2zi92+cvnJOcdx8S/vZc2adWPTd9qxC/sO6MMjt5/HhJvPYs++O6z9bIftt+Xvd13AhJvPYt8BfcrRZCtg3P3PcODg3QA48oABbNl2C/b68kUM/sqlnH7CgXTqsHWZW1h+qlKupdxKcU7xWGAAsAfQGXhW0iTg68BDETE6nfRxq3S97hGxO4CkjhuqMJ1KKJlOqHXlHaEftv/uLF32HjNfms+QgTuvLW9VXUXH9ltx6MlXMbDvjtz+k1MY8OVLWLz0Xfr/10UsW/E+e+zak99ddRr7fm00773/URm/hdX55Z0PU11dxTFf3AuAGbNfp7q6iqn3XsaK9z7guJG/ZP9Bu7Dj9p3L3NLyag69wDxKEYr7A3en4w0XS/o7sDfwLHCbpNbAvRExQ9K/gM9Iug64H3h4QxVGxC3ALQBVW3UpOA1QczR4j88wfGh/Dt2vH23atKb91m25+bITWbhkOX95fCYA02e/zpoItu3YjreXr+TjFckh9cyX5jNvwVL67NCFGXPeKOfXMOCPf53CY0/OYuy1I9f+p7/30ekcsM+utG5VTedO7RnUvzfPvzR/8w5FVU4oluKc4gZ/ExExCRgGLAR+K+nEiFhG0qOcCIxk/Zl1W4zLbhjP7kf9H3scfTGn/vB2Jj/7CqdfdCcPTHyeYXvvAkCfHbqwRetWvL18Jdt2bEdVelixY/dt+UzP7Xht4dJyfgUDHn9mDjf97jFuu+I7bNl2i7Xl3bt25B/TXyUi+ODDVTw363V22qFrGVtafiI515pnKbdS9BQnAadLGgNsQxKEP5C0I7AwIm6VtDUwUNIDwMcRcY+kfwJ3lKB9zcZd45/i+ou+wZNjf8jHq2v57iW/BWC/PXdi1BlHUltTS+2a4Nwrx7L83Q/K3NrNy8hLxvD0c//knRUr2fvYizn3lMO5/q5H+Xh1DV8/50YABvbrxRXnHc9Jxwzl3Ct+zyEn/pSI4PgjBrPbTtuX+RuUW/O4iJKHIopz9Fl3S46S38TPgMNJZrz9cUT8QdJJwA+A1cBK4ESgA3A763qwoyLir4X2U7VVl2jz2eOL8h2sOOZPvrbcTbBGOGTYYGZMn7ZJidb207vEjiddl2vdV342fFpDM2+XQtF6inX3KEaSuj9Il+znY1j3oJmsgcVqk5mVSTM5NM7DI1rMrOgEa8+LN3cORTMrCfcUzcwyKuVCi0PRzIrP5xTNzNYR8iSzZmZZldJTrIzoNrOK1xSz5EhqK2mKpJmSZkm6NC2/RNLCdIKZGZKOyGwzStJcSS9LOmxj7XRP0cyKr+nOKa4CDoqIlem8CU9IqhvgcU1EXLXebqW+wAigH7A98KikXQo9+9k9RTMrumTs86b3FCNRN9Fo63QpNCzvaGBsRKyKiHnAXGCfQvtwKJpZSTRiQojOkqZmltPWr0fVkmYAS4BHIuKZ9KMzJT0v6TZJndKy7sD8zOYL0rIG+fDZzEqiESNalhYa+5we+g5I51v9s6TdgZuAy0l6jZcDVwOnsOFZugpO+OCeopkVn5r+cQQRsZxkmsHhEbE4ImojYg1wK+sOkRcAPTOb9QDeLFSvQ9HMiq6p5lOUtF3djPyStgQOAV6S1C2z2jHAi+nr8cAISW0k9QZ2BqYU2ocPn82sBJpsPsVuwJj0ESZVwLiImCDpt5IGkBwavwacDhARsySNA2YDNcDIQleewaFoZiXSFJkYEc8De26g/FsFthkNjM67D4eimRWfPHWYmdladfcpVgKHopmVhEPRzCyjQjLRoWhmpeGeoplZHU8ya2a2TjLJbGWkokPRzEqiqkK6ig5FMyuJCslEh6KZFZ/kCy1mZuupkFOKDYeipOsoMO9YRHy/KC0ysxapJVxomVqyVphZiyaSK9CVoMFQjIgx2feSto6I94vfJDNriSqko7jxSWYl7StpNjAnfb+HpBuL3jIzazlyzrrdHC7G5Jl5+1rgMOBtgIiYCQwrZqPMrOVpipm3SyHX1eeImF8vwQvOXGtmliVa1s3b8yXtB4SkLYDvkx5Km5nlVSlXn/McPp8BjCR5VupCYED63swsl7yHzs2hM7nRnmJELAW+UYK2mFkLVimHz3muPn9G0l8kvSVpiaT7JH2mFI0zs5ZDOZdyy3P4/HtgHMmjBbcH/gjcXcxGmVnL0xS35EhqK2mKpJmSZkm6NC3fRtIjkl5Nf3bKbDNK0lxJL0s6bGPtzBOKiojfRkRNutxFgeF/Zmb1JVef8y0bsQo4KCL2ILm+MVzS54ELgcciYmfgsfQ9kvoCI4B+wHDgxvSZ0Q1qMBTT5N0GeFzShZJ6SdpR0vnA/Tl+D2ZmCSWTzOZZConEyvRt63QJ4GigbhTeGODL6eujgbERsSoi5gFzgX0K7aPQhZZp6c7qWnl6tm3A5QVbb2aW0YjRKp0lZedeuCUibsnUU02STzsBN0TEM5K6RsQigIhYJKlLunp34OlMXQvSsgYVGvvcO+83MDMrpO7wOaelETGooQ8johYYIKkj8GdJu29k15+ootDOc41oSXfaF2ibadidebY1M4Omn2Q2IpZLmkhyrnCxpG5pL7EbsCRdbQHQM7NZD+DNQvXmuSXnYuC6dDkQ+BnwpUZ/AzPbrDXFLTmStkt7iEjaEjgEeAkYD5yUrnYScF/6ejwwQlIbSb2BnYEphfaRp6f4FWAP4LmIOFlSV+DXObYzMwOSkSrVTTPMrxswJj2vWAWMi4gJkp4Cxkk6FXgD+CpARMySNA6YDdQAI9PD7wblCcUPI2KNpBpJHUi6pb5528wapSkOnyPieWDPDZS/DRzcwDajgdF595EnFKem3dVbSa74rGQj3U8zs/oqZJRfrrHP/52+/JWkB4EOaVqbmeUiVDFjnws9uGpgoc8iYnpxmmRmLU4zmQEnj0I9xasLfBbAQU3clv9MVTW0bVfuVlgjtGvrJ+tWkuomSrPm8KiBPArdvH1gKRtiZi2XaLpwLTb/yTazkqiQibcdimZWGg5FM7NU8qiBykjFPMP8JOmbki5K3+8gqeDUO2Zm9TXRfIrFb2eOdW4E9gVOSN+/B9xQtBaZWYvUYh5cBQyOiIGSngOIiGXpo07NzHIR0Ko5JF4OeUJxdTr4OiCZpQJYU9RWmVmLUyGZmCsUfwn8GegiaTTJrDk/KmqrzKxFkVrAML86EfE7SdNIZqAQ8OWImFP0lplZi1IhmbjxUJS0A/AB8JdsWUS8UcyGmVnL0hyuLOeR5/D5ftY9wKot0Bt4meSRgWZmGyWabJLZostz+Nw/+z6dPef0BlY3M/ukZnIPYh6NHtESEdMl7V2MxphZy6WNPoGlechzTvGczNsqYCDwVtFaZGYtTiMfcVpWeXqK7TOva0jOMd5TnOaYWUvVIkIxvWm7XUT8oETtMbMWquInhJDUKn0UYIOPJTAzyyN5xGm+pXA96inpcUlzJM2SdFZafomkhZJmpMsRmW1GSZor6WVJh22srYV6ilNIAnGGpPHAH4H36z6MiD9trHIzszpNNKKlBjg3veDbHpgm6ZH0s2si4qrsypL6AiNIbiHcHnhU0i6Fnv2c55ziNsDbJM9kqbtfMQCHopnl0lQXWiJiEbAoff2epDlA9wKbHA2MjYhVwDxJc4F9gKca2qBQKHZJrzy/yLowXNu2fF/BzCzR1KcUJfUC9gSeAYYAZ0o6EZhK0ptcRhKYT2c2W0DhEC04n2I10C5d2mde1y1mZjmJqpwL0FnS1Mxy2idqk9qR3AXzPxHxLnAT0AcYQNKTvHrtjj+pYKeuUE9xUURctvEva2ZWmGhUT3FpRAxqsC6pNUkg/q7u2kZELM58fiswIX27AOiZ2bwH8GahnRfqKVbG9XMza/4EraqUaylYTXJfz2+AORHxi0x5t8xqx5Cc9gMYD4yQ1EZSb2BnkovIDSrUUzy4YOvMzHJqZE+xkCHAt4AXJM1Iy34InCBpAMmh8Wuk8zNExCxJ44DZJFeuRxa68gwFQjEi3tnk5puZpZrilpyIeIINH8U+UGCb0cDovPvwI07NrCQqZECLQ9HMik/ke3Roc+BQNLPiU5ONaCk6h6KZFV0yosWhaGa2VmVEokPRzEqkQjqKDkUzKwVVzHyKDkUzKzpffTYzq8cXWszM6qhyHkfgUDSzovPhs5lZPe4pmpllVEYkOhTNrAQEVLunaGa2ToVkokPRzEpBqEIOoB2KZlYS7imamaWSW3IqIxUdimZWfHJP0cxsPR7mZ2aWSiaZLXcr8nEomllJVMrV50oZjmhmFU7KtxSuQz0lPS5pjqRZks5Ky7eR9IikV9OfnTLbjJI0V9LLkg7bWDvdUyyjqirx+K3fY9HSFYy4YAwXnHwIJ/7X3ry9/H0ALr/lIR55+mUG7taDa39wLJCMH73ytke5f/KscjZ9s3PmZXfx0BMv0rlTe576w/8CsGzF+5zyw9t4Y9E77NBtG26/4lQ6dtgKgBdfXcg5V9zNeys/QlXib2POp22b1uX8CmXXRD3FGuDciJguqT0wTdIjwLeBxyLiSkkXAhcCF0jqC4wA+gHbA49K2iUiahvaQdlDUdIDwNcjYnm521JqZ3x1CK+8voT2W7dZW3bTuCe4fuzk9dab86/FHPid66mtXUPXbdsz+fazePDJOdTWril1kzdbJxz1eb5z/Bc44+I715ZdM+YRhu39Wc7+9he55o6HuWbMw1z6vS9TU1PL6ReN4VeXnkj/XXrwzvKVtG5VXcbWl19TnVOMiEXAovT1e5LmAN2Bo4ED0tXGABOBC9LysRGxCpgnaS6wD/BUQ/so++FzRByxOQbi9tt14Iv77sqdE57d6Lofrlq9NgDbbNGKiCh286yeIQN3olPaC6zz178/zwlHDQbghKMG88DE5wH42zMv0W+n7vTfpQcA23RsR3V12f+rlZdEVc4F6CxpamY5bcNVqhewJ/AM0DUNzLrg7JKu1h2Yn9lsQVrWoKL3FCWdD3wUEb+UdA2wR0QcJOlg4GRgf2AQ0A74K/AEsB+wEDg6Ij4sdhvL4Sff/y8uvvGvtNuqzXrl3zl2P0YMH8hzLy3kR9ffz4qVydffq29PrrvwK/Ts2pEzfjzOvcRmYMk77/Hpzp8C4NOdP8Vby94D4J+vL0GC4753PUuXreTYL+7FWSceWs6mNguN6CgujYhBBeuS2gH3AP8TEe8WmJZsQx8U7FWU4s/XJGBo+noQ0E5Sa5IwnFxv3Z2BGyKiH7AcOG5DFUo6re6vSKz+oEjNLp7D9tuVpctWMvOVheuV33bv0+w54mcMPfmXLH77XX585pFrP5s2ez77nXgNB592PWd/8wDabFH2Mx/WgJraWp6e+S9uufzb/PXX53D/xJn8fcrL5W5WWdU99zlnT7FwXUl+3AP8LiL+lBYvltQt/bwbsCQtXwD0zGzeA3izUP2lCMVpwF7pSdFVJMfyg0iCsn4ozouIGZntem2owoi4JSIGRcQgtd5qQ6s0a4P778jwIX2ZOe4CfnPJCQwd2Ieb/+9rvLVsJWvWBBHBmL88y1679fjEtq+8/hYffPQxu/XuWoaWW1aXbdrz76UrAPj30hVs16k9ANt37ciQPXdi247t2KrtFhy6Xz9mvjy/UFWbBeVcCtaRdAl/A8yJiF9kPhoPnJS+Pgm4L1M+QlIbSb1JOl5TCu2j6KEYEauB10gOlZ8kCcIDgT7AnHqrr8q8rqUZXAgqhstufojdj7uCPY7/KadecjeTp/+T0y//A123bb92naOG9WPOvMUA7NCt09pzUj27dmSnHbbjjX8vK0vbbZ3hw/pz94RnALh7wjMc/oXPAXDw5/sya+5CPvjoY2pqavnH9Ll8tveny9nU5qEpUhGGAN8CDpI0I12OAK4EDpX0KnBo+p6ImAWMA2YDDwIjC115htKFziTgPOAU4AXgF8C0iIhKmaK8FC797uH032l7guCNRcs4+6o/A7Dv53px1jcOoKamljURnPeLe3lnReWdNqhkp/7v7fxj2qu8vXwl/Y78EReedgRnn3QoJ4+6jbvGP0WPrp2448pTAejYYSv+++sHcfCJPwOJQ4f047D9dy/zNyi/phjmFxFP0HB0HtzANqOB0Xn3oVJcyUwvqjwIdIyI9yW9AvwqIn4h6TXWXWiZEBG7p9ucB7SLiEsK1V3Vrlu06X9SoVWsmVk2+cpyN8EaYcjgQUybNnWTEm23/nvGnfdNzLXuPn06TtvYhZZiKklPMSIeA1pn3u+Sed0rfbkU2D1TflUp2mZmJVIhB4Ut8pydmTUvyenCykhFh6KZFZ/nUzQzW1+FZKJD0cxKQVTKnSYORTMriQrJRIeimRVfvvuymweHopmVRoWkokPRzErCt+SYmWX4nKKZWR3fp2hmtj4fPpuZpYR7imZm66mQTHQomlmJVEgqOhTNrCSaYpLZUnAomllJVEYkOhTNrFQqJBUdimZWdJ5k1swsq4Ju3i7Fc5/NzJroCacg6TZJSyS9mCm7RNLCeo89rftslKS5kl6WdNjG6ncomlkJJJPM5llyuAMYvoHyayJiQLo8ACCpLzAC6Jduc6Ok6kKVOxTNrCSkfMvGRMQk4J2cuz0aGBsRqyJiHjAX2KfQBg5FMyu6vIfOaSZ2ljQ1s5yWczdnSno+PbzulJZ1B+Zn1lmQljXIoWhmpZE/FZdGxKDMckuO2m8C+gADgEXA1Zm91heFKvLVZzMriWLekhMRi9fuR7oVmJC+XQD0zKzaA3izUF3uKZpZSTTVOcUN161umbfHAHVXpscDIyS1kdQb2BmYUqgu9xTNrPgEVU3UUZR0N3AAybnHBcDFwAGSBpAcGr8GnA4QEbMkjQNmAzXAyIioLVS/Q9HMSqRpUjEiTthA8W8KrD8aGJ23foeimRWdJ5k1M6unQjLRoWhmpeGeoplZRs4hfGXnUDSzkqiMSHQomlkJbMo9iKXmUDSzkvAks2ZmWZWRiQ5FMyuNCslEh6KZlYL8iFMzszqVNKLFs+SYmWW4p2hmJVEpPUWHopmVhG/JMTOr45u3zczWqaQLLQ5FMysJHz6bmWW4p2hmllEhmehQNLMSqZBUdCiaWdEJKmaYnyKi3G3YJJLeAl4vdzuKoDOwtNyNsEZpqf9mO0bEdptSgaQHSX4/eSyNiOGbsr9NUfGh2FJJmhoRg8rdDsvP/2Ytg8c+m5llOBTNzDIcis3XLeVugDWa/81aAJ9TNDPLcE/RzCzDoWhmluFQLANJK8vdBmtakh6Q1LHc7bBN53OKZSBpZUS0K3c7zOyT3FMsIyV+LulFSS9I+lpa3k3SJEkz0s+GSqqWdEdm3bPL3f7NiaTzJX0/fX2NpL+lrw+WdJek1yR1ltRL0hxJt0qaJelhSVuWt/XWGA7F8joWGADsARwC/FxSN+DrwEMRUffZjHS97hGxe0T0B24vU5s3V5OAoenrQUA7Sa2B/YHJ9dbdGbghIvoBy4HjStZK22QOxfLaH7g7ImojYjHwd2Bv4FngZEmXAP0j4j3gX8BnJF0naTjwbrkavZmaBuwlqT2wCniKJByH8slQnBcRMzLb9SpVI23TORTLa4PThkTEJGAYsBD4raQTI2IZSa9xIjAS+HWpGmkQEauB14CTgSdJgvBAoA8wp97qqzKva/FsVBXFoVhek4CvpecLtyMJwimSdgSWRMStwG+AgZI6A1URcQ/wf8DAsrV68zUJOC/9ORk4A5gRvlrZovgvWHn9GdgXmAkEcH5E/FvSScAPJK0GVgInAt2B2yXV/SEbVY4Gb+YmA/8LPBUR70v6iE8eOluF8y05ZmYZPnw2M8twKJqZZTgUzcwyHIpmZhkORTOzDIdiCyepNjOG+o+SttqEuu6Q9JX09a8l9S2w7gGS9vsP9vFaek9mrvJ66zRq9iFJl0g6r7FttJbNodjyfRgRAyJid+BjkhuO15JU/Z9UGhH/LyJmF1jlAKDRoWhWbg7FzctkYKe0F/e4pN8DL6Qjan4u6VlJz0s6HdbO4nO9pNmS7ge61FUkaaKkQenr4ZKmS5op6TFJvUjC9+y0lzpU0naS7kn38aykIem226YzyTwn6WYaGPqYJeleSdPSWWhOq/fZ1WlbHktHCSGpj6QH020mS9q1KX6Z1jJ5RMtmQlIr4HDgwbRoH2D3iJiXBsuKiNhbUhvgH5IeBvYEPgv0B7oCs4Hb6tW7HXArMCyta5uIeEfSr4CVEXFVut7vgWsi4glJOwAPAbsBFwNPRMRlko4E1gu5BpyS7mNL4FlJ90TE28DWwPSIOFfSRWndZ5I8UOqMiHhV0mDgRuCg/+DXaJsBh2LLt6WkuhlbJpOMpd4PmBIR89LyLwKfqztfCHyKZPqrYaSz+ABv1s0hWM/ngUl1dUXEOw204xCgr7S2I9ghnXFmGMkUakTE/ZKW5fhO35d0TPq6Z9rWt4E1wB/S8ruAP0lql37fP2b23SbHPmwz5VBs+T5M52VcKw2H97NFwPci4qF66x1BMia7EOVYB5JTNftGxIcbaEvusaaSDiAJ2H0j4gNJE4G2Dawe6X6X1/8dmDXE5xQNkkPZ76aTpiJpF0lbk8wGMyI959iNZKqs+p4CviCpd7rtNmn5e0D7zHoPkxzKkq5XF1KTgG+kZYcDnTbS1k8By9JA3JWkp1qnCqjr7X6d5LD8XWCepK+m+5CkPTayD9uMORQNkrkZZwPTJb0I3ExyFPFn4FXgBeAmkklw1xMRb5GcB/yTpJmsO3z9C3BM3YUW4PvAoPRCzmzWXQW/FBgmaTrJYfwbG2nrg0ArSc8DlwNPZz57H+gnaRrJOcPL0vJvAKem7ZsFHJ3jd2KbKc+SY2aW4Z6imVmGQ9HMLMOhaGaW4VA0M8twKJqZZToVmVoAAAAQSURBVDgUzcwyHIpmZhn/H4qEvcfk7EnHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues, display_labels=[\"loss\", \"win\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Deep Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=10, activation='relu', input_dim=6))\n",
    "deep_model.add(Dense(units=8, activation='relu'))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=4, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3456 samples\n",
      "Epoch 1/100\n",
      "3456/3456 - 1s - loss: 0.6942 - accuracy: 0.5145\n",
      "Epoch 2/100\n",
      "3456/3456 - 0s - loss: 0.6926 - accuracy: 0.5214\n",
      "Epoch 3/100\n",
      "3456/3456 - 0s - loss: 0.6922 - accuracy: 0.5229\n",
      "Epoch 4/100\n",
      "3456/3456 - 0s - loss: 0.6921 - accuracy: 0.5197\n",
      "Epoch 5/100\n",
      "3456/3456 - 0s - loss: 0.6917 - accuracy: 0.5214\n",
      "Epoch 6/100\n",
      "3456/3456 - 0s - loss: 0.6919 - accuracy: 0.5243\n",
      "Epoch 7/100\n",
      "3456/3456 - 0s - loss: 0.6916 - accuracy: 0.5252\n",
      "Epoch 8/100\n",
      "3456/3456 - 0s - loss: 0.6913 - accuracy: 0.5223\n",
      "Epoch 9/100\n",
      "3456/3456 - 0s - loss: 0.6911 - accuracy: 0.5229\n",
      "Epoch 10/100\n",
      "3456/3456 - 0s - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 11/100\n",
      "3456/3456 - 0s - loss: 0.6907 - accuracy: 0.5307\n",
      "Epoch 12/100\n",
      "3456/3456 - 0s - loss: 0.6904 - accuracy: 0.5327\n",
      "Epoch 13/100\n",
      "3456/3456 - 0s - loss: 0.6902 - accuracy: 0.5324\n",
      "Epoch 14/100\n",
      "3456/3456 - 0s - loss: 0.6901 - accuracy: 0.5284\n",
      "Epoch 15/100\n",
      "3456/3456 - 0s - loss: 0.6897 - accuracy: 0.5307\n",
      "Epoch 16/100\n",
      "3456/3456 - 0s - loss: 0.6892 - accuracy: 0.5341\n",
      "Epoch 17/100\n",
      "3456/3456 - 0s - loss: 0.6887 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "3456/3456 - 0s - loss: 0.6888 - accuracy: 0.5362\n",
      "Epoch 19/100\n",
      "3456/3456 - 0s - loss: 0.6887 - accuracy: 0.5399\n",
      "Epoch 20/100\n",
      "3456/3456 - 0s - loss: 0.6882 - accuracy: 0.5428\n",
      "Epoch 21/100\n",
      "3456/3456 - 0s - loss: 0.6886 - accuracy: 0.5318\n",
      "Epoch 22/100\n",
      "3456/3456 - 0s - loss: 0.6876 - accuracy: 0.5391\n",
      "Epoch 23/100\n",
      "3456/3456 - 0s - loss: 0.6876 - accuracy: 0.5376\n",
      "Epoch 24/100\n",
      "3456/3456 - 0s - loss: 0.6877 - accuracy: 0.5336\n",
      "Epoch 25/100\n",
      "3456/3456 - 0s - loss: 0.6870 - accuracy: 0.5422\n",
      "Epoch 26/100\n",
      "3456/3456 - 0s - loss: 0.6868 - accuracy: 0.5480\n",
      "Epoch 27/100\n",
      "3456/3456 - 0s - loss: 0.6865 - accuracy: 0.5544\n",
      "Epoch 28/100\n",
      "3456/3456 - 0s - loss: 0.6859 - accuracy: 0.5506\n",
      "Epoch 29/100\n",
      "3456/3456 - 0s - loss: 0.6859 - accuracy: 0.5460\n",
      "Epoch 30/100\n",
      "3456/3456 - 0s - loss: 0.6860 - accuracy: 0.5477\n",
      "Epoch 31/100\n",
      "3456/3456 - 0s - loss: 0.6857 - accuracy: 0.5535\n",
      "Epoch 32/100\n",
      "3456/3456 - 0s - loss: 0.6850 - accuracy: 0.5532\n",
      "Epoch 33/100\n",
      "3456/3456 - 0s - loss: 0.6845 - accuracy: 0.5518\n",
      "Epoch 34/100\n",
      "3456/3456 - 0s - loss: 0.6848 - accuracy: 0.5593\n",
      "Epoch 35/100\n",
      "3456/3456 - 0s - loss: 0.6839 - accuracy: 0.5570\n",
      "Epoch 36/100\n",
      "3456/3456 - 0s - loss: 0.6842 - accuracy: 0.5512\n",
      "Epoch 37/100\n",
      "3456/3456 - 0s - loss: 0.6846 - accuracy: 0.5541\n",
      "Epoch 38/100\n",
      "3456/3456 - 0s - loss: 0.6831 - accuracy: 0.5602\n",
      "Epoch 39/100\n",
      "3456/3456 - 0s - loss: 0.6832 - accuracy: 0.5564\n",
      "Epoch 40/100\n",
      "3456/3456 - 0s - loss: 0.6829 - accuracy: 0.5654\n",
      "Epoch 41/100\n",
      "3456/3456 - 0s - loss: 0.6824 - accuracy: 0.5573\n",
      "Epoch 42/100\n",
      "3456/3456 - 0s - loss: 0.6819 - accuracy: 0.5674\n",
      "Epoch 43/100\n",
      "3456/3456 - 0s - loss: 0.6822 - accuracy: 0.5642\n",
      "Epoch 44/100\n",
      "3456/3456 - 0s - loss: 0.6820 - accuracy: 0.5663\n",
      "Epoch 45/100\n",
      "3456/3456 - 0s - loss: 0.6811 - accuracy: 0.5709\n",
      "Epoch 46/100\n",
      "3456/3456 - 0s - loss: 0.6813 - accuracy: 0.5668\n",
      "Epoch 47/100\n",
      "3456/3456 - 0s - loss: 0.6810 - accuracy: 0.5689\n",
      "Epoch 48/100\n",
      "3456/3456 - 0s - loss: 0.6803 - accuracy: 0.5729\n",
      "Epoch 49/100\n",
      "3456/3456 - 0s - loss: 0.6806 - accuracy: 0.5694\n",
      "Epoch 50/100\n",
      "3456/3456 - 0s - loss: 0.6804 - accuracy: 0.5674\n",
      "Epoch 51/100\n",
      "3456/3456 - 0s - loss: 0.6798 - accuracy: 0.5680\n",
      "Epoch 52/100\n",
      "3456/3456 - 0s - loss: 0.6800 - accuracy: 0.5723\n",
      "Epoch 53/100\n",
      "3456/3456 - 0s - loss: 0.6792 - accuracy: 0.5706\n",
      "Epoch 54/100\n",
      "3456/3456 - 0s - loss: 0.6798 - accuracy: 0.5767\n",
      "Epoch 55/100\n",
      "3456/3456 - 0s - loss: 0.6789 - accuracy: 0.5758\n",
      "Epoch 56/100\n",
      "3456/3456 - 0s - loss: 0.6791 - accuracy: 0.5712\n",
      "Epoch 57/100\n",
      "3456/3456 - 0s - loss: 0.6779 - accuracy: 0.5764\n",
      "Epoch 58/100\n",
      "3456/3456 - 0s - loss: 0.6776 - accuracy: 0.5767\n",
      "Epoch 59/100\n",
      "3456/3456 - 0s - loss: 0.6772 - accuracy: 0.5770\n",
      "Epoch 60/100\n",
      "3456/3456 - 0s - loss: 0.6773 - accuracy: 0.5767\n",
      "Epoch 61/100\n",
      "3456/3456 - 0s - loss: 0.6766 - accuracy: 0.5830\n",
      "Epoch 62/100\n",
      "3456/3456 - 0s - loss: 0.6755 - accuracy: 0.5802\n",
      "Epoch 63/100\n",
      "3456/3456 - 0s - loss: 0.6765 - accuracy: 0.5813\n",
      "Epoch 64/100\n",
      "3456/3456 - 0s - loss: 0.6759 - accuracy: 0.5859\n",
      "Epoch 65/100\n",
      "3456/3456 - 0s - loss: 0.6751 - accuracy: 0.5868\n",
      "Epoch 66/100\n",
      "3456/3456 - 0s - loss: 0.6751 - accuracy: 0.5825\n",
      "Epoch 67/100\n",
      "3456/3456 - 0s - loss: 0.6748 - accuracy: 0.5810\n",
      "Epoch 68/100\n",
      "3456/3456 - 0s - loss: 0.6751 - accuracy: 0.5802\n",
      "Epoch 69/100\n",
      "3456/3456 - 0s - loss: 0.6742 - accuracy: 0.5856\n",
      "Epoch 70/100\n",
      "3456/3456 - 0s - loss: 0.6743 - accuracy: 0.5836\n",
      "Epoch 71/100\n",
      "3456/3456 - 0s - loss: 0.6735 - accuracy: 0.5851\n",
      "Epoch 72/100\n",
      "3456/3456 - 0s - loss: 0.6734 - accuracy: 0.5804\n",
      "Epoch 73/100\n",
      "3456/3456 - 0s - loss: 0.6736 - accuracy: 0.5883\n",
      "Epoch 74/100\n",
      "3456/3456 - 0s - loss: 0.6729 - accuracy: 0.5894\n",
      "Epoch 75/100\n",
      "3456/3456 - 0s - loss: 0.6732 - accuracy: 0.5816\n",
      "Epoch 76/100\n",
      "3456/3456 - 0s - loss: 0.6722 - accuracy: 0.5874\n",
      "Epoch 77/100\n",
      "3456/3456 - 0s - loss: 0.6727 - accuracy: 0.5877\n",
      "Epoch 78/100\n",
      "3456/3456 - 0s - loss: 0.6718 - accuracy: 0.5952\n",
      "Epoch 79/100\n",
      "3456/3456 - 0s - loss: 0.6725 - accuracy: 0.5851\n",
      "Epoch 80/100\n",
      "3456/3456 - 0s - loss: 0.6711 - accuracy: 0.5888\n",
      "Epoch 81/100\n",
      "3456/3456 - 0s - loss: 0.6716 - accuracy: 0.5923\n",
      "Epoch 82/100\n",
      "3456/3456 - 0s - loss: 0.6723 - accuracy: 0.5868\n",
      "Epoch 83/100\n",
      "3456/3456 - 0s - loss: 0.6717 - accuracy: 0.5880\n",
      "Epoch 84/100\n",
      "3456/3456 - 0s - loss: 0.6707 - accuracy: 0.5926\n",
      "Epoch 85/100\n",
      "3456/3456 - 0s - loss: 0.6701 - accuracy: 0.5911\n",
      "Epoch 86/100\n",
      "3456/3456 - 0s - loss: 0.6720 - accuracy: 0.5943\n",
      "Epoch 87/100\n",
      "3456/3456 - 0s - loss: 0.6706 - accuracy: 0.5891\n",
      "Epoch 88/100\n",
      "3456/3456 - 0s - loss: 0.6706 - accuracy: 0.5903\n",
      "Epoch 89/100\n",
      "3456/3456 - 0s - loss: 0.6696 - accuracy: 0.5897\n",
      "Epoch 90/100\n",
      "3456/3456 - 0s - loss: 0.6704 - accuracy: 0.5911\n",
      "Epoch 91/100\n",
      "3456/3456 - 0s - loss: 0.6697 - accuracy: 0.5862\n",
      "Epoch 92/100\n",
      "3456/3456 - 0s - loss: 0.6695 - accuracy: 0.5926\n",
      "Epoch 93/100\n",
      "3456/3456 - 0s - loss: 0.6698 - accuracy: 0.5975\n",
      "Epoch 94/100\n",
      "3456/3456 - 0s - loss: 0.6688 - accuracy: 0.5917\n",
      "Epoch 95/100\n",
      "3456/3456 - 0s - loss: 0.6692 - accuracy: 0.5923\n",
      "Epoch 96/100\n",
      "3456/3456 - 0s - loss: 0.6685 - accuracy: 0.5952\n",
      "Epoch 97/100\n",
      "3456/3456 - 0s - loss: 0.6685 - accuracy: 0.5964\n",
      "Epoch 98/100\n",
      "3456/3456 - 0s - loss: 0.6695 - accuracy: 0.5906\n",
      "Epoch 99/100\n",
      "3456/3456 - 0s - loss: 0.6688 - accuracy: 0.5992\n",
      "Epoch 100/100\n",
      "3456/3456 - 0s - loss: 0.6677 - accuracy: 0.5943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x101917f048>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1 - 0s - loss: 0.7250 - accuracy: 0.5269\n",
      "Deep Neural Network - Loss: 0.7092590679725012, Accuracy: 0.5269097089767456\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"WinSpread\"]\n",
    "target_names = [\"loss\", \"win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>net_points</th>\n",
       "      <th>net_yard</th>\n",
       "      <th>net_turn</th>\n",
       "      <th>weekly_rank</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>-14</td>\n",
       "      <td>-147</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-67</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>-2</td>\n",
       "      <td>25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>159</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>144</td>\n",
       "      <td>-4</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-286</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>-27</td>\n",
       "      <td>-144</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-78</td>\n",
       "      <td>-4</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>-14</td>\n",
       "      <td>-59</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>-31</td>\n",
       "      <td>-159</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>-40</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-68</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-78</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-37</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-127</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    home  net_points  net_yard  net_turn  weekly_rank  spread\n",
       "0      1           0         0         0            2    -5.5\n",
       "1      0           0         0         0            6     5.5\n",
       "2      1           0         0         0           17    -1.0\n",
       "3      0           0         0         0           15     1.0\n",
       "4      1           0         0         0           27    -3.0\n",
       "5      0           0         0         0           31     3.0\n",
       "6      1           0         0         0           19    -3.0\n",
       "7      0           0         0         0           20     3.0\n",
       "8      1           0         0         0           21     3.0\n",
       "9      0           0         0         0            9    -3.0\n",
       "10     1           0         0         0           24     3.0\n",
       "11     0           0         0         0            7    -3.0\n",
       "12     1           0         0         0           32     4.5\n",
       "13     0           0         0         0           13    -4.5\n",
       "14     1           0         0         0           14     6.5\n",
       "15     0           0         0         0            1    -6.5\n",
       "16     1           0         0         0           12    -7.0\n",
       "17     0           0         0         0           22     7.0\n",
       "18     1           0         0         0           29    -3.0\n",
       "19     0           0         0         0           26     3.0\n",
       "20     1           0         0         0            3    -6.0\n",
       "21     0           0         0         0            4     6.0\n",
       "22     1           0         0         0           10    -6.0\n",
       "23     0           0         0         0           28     6.0\n",
       "24     1           0         0         0           30    -2.0\n",
       "25     0           0         0         0           25     2.0\n",
       "26     1           0         0         0            8    -6.5\n",
       "27     0           0         0         0           18     6.5\n",
       "28     1           0         0         0           11    -2.5\n",
       "29     0           0         0         0            5     2.5\n",
       "30     1           0         0         0           16    -3.0\n",
       "31     0           0         0         0           23     3.0\n",
       "32     1         -14      -147         0           20    -3.0\n",
       "33     0           3       -67        -1           15     3.0\n",
       "34     1          14       147         0           12    -6.0\n",
       "35     0          17        96        -2           25     6.0\n",
       "36     1           3        78         1           14     7.0\n",
       "37     0          31       159        -2            2    -7.0\n",
       "38     1          27       144        -4            9   -10.0\n",
       "39     0          -1      -286         0           26    10.0\n",
       "40     1         -27      -144         4           32     7.0\n",
       "41     0           7       -78        -4            6    -7.0\n",
       "42     1         -14       -59         1           28     4.0\n",
       "43     0         -31      -159         2           11    -4.0\n",
       "44     1         -10       -40        -1           22    -2.0\n",
       "45     0           3       -68        -1           17     2.0\n",
       "46     1          -3       -78        -1           16   -10.0\n",
       "47     0         -21       -37         1           31    10.0\n",
       "48     1          -3      -127        -1           27     3.5\n",
       "49     0          10        40         1            5    -3.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=['Win', 'WinSpread'],axis=1)\n",
    "feature_names = data.columns\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4982638888888889"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   55.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [400, 450, 500, 550, 600]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Support vector machine linear classifier\n",
    "model = SVC()\n",
    "\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "# 'C': regularization parameter: lower C means stronger regularization (\"softer\" margins)\n",
    "# 'rbf': \"Radial Basis Function\" kernel is a Gaussian kernel (for non-linear boundaries)\n",
    "param_grid = {\n",
    "    'n_estimators': [400,450,500,550,600],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "# Note: verbose doesn't work in parallel\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5442708333333334"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, criterion='entropy')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.24502180348951216, 'net_yard'),\n",
       " (0.22046672433042874, 'net_points'),\n",
       " (0.19508208183387113, 'spread'),\n",
       " (0.16031578753624487, 'weekly_rank'),\n",
       " (0.14826382286299145, 'net_turn'),\n",
       " (0.030849779946951535, 'home')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(rf, X_test, y_test, cmap=plt.cm.Blues, display_labels=[\"loss\", \"win\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.56      0.57      0.56       593\n",
      "         win       0.53      0.51      0.52       559\n",
      "\n",
      "    accuracy                           0.54      1152\n",
      "   macro avg       0.54      0.54      0.54      1152\n",
      "weighted avg       0.54      0.54      0.54      1152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions, target_names=[\"loss\", \"win\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
